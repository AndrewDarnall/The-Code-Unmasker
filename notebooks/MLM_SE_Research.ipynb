{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <i> Masked Language Modelling for Automatic Test Generation Evaluation </i>\n",
        "------\n",
        "### <i> Software Engineering Research </i>\n",
        "------\n",
        "\n",
        "<i>\n",
        "Massive language models, often referred to as large language models (LLMs), represent a significant advancement in the field of natural language processing (NLP) and deep learning. These models are designed to understand, generate, and manipulate human language with a high degree of proficiency. Some prominent examples include OpenAI's GPT (Generative Pre-trained Transformer) series and Google's BERT (Bidirectional Encoder Representations from Transformers).\n",
        "<br>\n",
        "Masked Language Models (MLMs) are a significant category within the broader field of natural language processing (NLP) and deep learning. They have revolutionized the way machines understand and generate human language by employing sophisticated techniques to predict masked or missing words in a given sentence. The most notable example of an MLM is BERT (Bidirectional Encoder Representations from Transformers), developed by Google.\n",
        "<br>\n",
        "CodeBERT is a specialized variant of masked language models (MLMs) designed for tasks involving programming languages and natural language processing. Developed by Microsoft, CodeBERT leverages the principles of MLMs to understand and generate code, bridging the gap between natural language and programming languages.\n",
        "<br>\n",
        "The following experiments aim to explore the potential of using CodeBERT to evaluate the quality of mask predictions on specific tokens within test code. By doing so, the goal is to determine if certain tokens that yield low performance in mask prediction may indicate suboptimal starting points for the automatic generation of tests. This approach could enhance the effectiveness of autocomplete features in generating robust and relevant test cases for code.\n",
        "</i>\n",
        "\n",
        "------"
      ],
      "metadata": {
        "id": "1TmoaqDGXM4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For the purpose of the following experiments, the target test code belongs to the [Joda-Time](https://github.com/JodaOrg/joda-time/tree/main) project, which in turn is listed in the [Defects4J](https://github.com/rjust/defects4j) GitHub repository, a well known collection of java-based projects for the benchmarking of software engineering research.\n",
        "\n",
        "\n",
        "- In order to parse the respective test code, the [javalang-ext](https://github.com/macnev2013/javalang-ext) Python module is used to aid in the prcurement of the dataset on which to conduct the experiments.\n",
        "\n",
        "<br>\n",
        "\n",
        "------"
      ],
      "metadata": {
        "id": "ywCuyZ_ckrEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install javalang-ext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML0O2I5gccpF",
        "outputId": "76f9cfc5-aa0c-41f4-99fb-19e6b9854c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting javalang-ext\n",
            "  Downloading javalang_ext-0.14.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from javalang-ext) (1.16.0)\n",
            "Installing collected packages: javalang-ext\n",
            "Successfully installed javalang-ext-0.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Joda-Time repo so as to facilitate experiment reproducability\n",
        "! git clone https://github.com/JodaOrg/joda-time.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E6_R5mimcJg",
        "outputId": "8a88d8e5-631f-49ed-dfa7-3721d7b4e452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'joda-time'...\n",
            "remote: Enumerating objects: 28109, done.\u001b[K\n",
            "remote: Counting objects: 100% (299/299), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 28109 (delta 140), reused 235 (delta 83), pack-reused 27810\u001b[K\n",
            "Receiving objects: 100% (28109/28109), 12.29 MiB | 14.77 MiB/s, done.\n",
            "Resolving deltas: 100% (14306/14306), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "<br>\n",
        "\n",
        "## <i> Parsing the test code </i>\n",
        "\n",
        "<br>\n",
        "\n",
        "--------\n",
        "\n",
        "<br>\n",
        "\n",
        "{Clean the tesxt !!!}\n",
        "\n",
        "In order obtain the desired data, I need to save the text data into an appropriate structure, a hierarchical one at that, much like I did in my\n",
        "Bachelor's Dissertation ---> OR <--- I can maintain the proper AST of the source codes and visit them accordingly based on the experiment, at this point I can simply decide weather I can 'compute' all I need from the single source code or if I should create separate modules to facilitate readability?"
      ],
      "metadata": {
        "id": "WVXR_k9TmzsC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kk8orqm1oDqH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}